{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee24619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INICIANDO CARGA DE DATOS CON RTIoTClassifier...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RTIoTClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 276\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mINICIANDO CARGA DE DATOS CON RTIoTClassifier...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# Crear instancia del clasificador\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m classifier = \u001b[43mRTIoTClassifier\u001b[49m(n_jobs=-\u001b[32m1\u001b[39m, use_feature_selection=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# NOTA: Reemplaza estas rutas con las rutas reales de tus archivos CSV\u001b[39;00m\n\u001b[32m    279\u001b[39m train_path = \u001b[33m\"\u001b[39m\u001b[33mtrain.csv\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Cambia por tu ruta real\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'RTIoTClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# ANÁLISIS EXPLORATORIO COMPLETO - RT-IoT2022\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Configuración para mostrar gráficos\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# =============================================================================\n",
    "# DEFINICIÓN DE LA CLASE RTIoTClassifier\n",
    "# =============================================================================\n",
    "\n",
    "class RTIoTClassifier:\n",
    "    def __init__(self, n_jobs=-1, use_feature_selection=True):\n",
    "        self.n_jobs = n_jobs if n_jobs != -1 else self._get_optimal_jobs()\n",
    "        self.use_feature_selection = use_feature_selection\n",
    "        print(f\"Configurado para usar {self.n_jobs} trabajos en paralelo\")\n",
    "\n",
    "        # Modelos\n",
    "        self.models = {\n",
    "            \"LogisticRegression\": LogisticRegression(\n",
    "                max_iter=500, random_state=42, n_jobs=self.n_jobs\n",
    "            ),\n",
    "            \"RandomForest\": RandomForestClassifier(\n",
    "                n_estimators=50, random_state=42, n_jobs=self.n_jobs\n",
    "            ),\n",
    "            \"SVM_Linear_Optimized\": LinearSVC(\n",
    "                random_state=42, max_iter=1000, dual=False\n",
    "            ),\n",
    "            \"DecisionTree\": DecisionTreeClassifier(random_state=42, max_depth=20),\n",
    "            \"KNN\": KNeighborsClassifier(n_neighbors=5, n_jobs=self.n_jobs),\n",
    "        }\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.feature_selector = None\n",
    "        self.results = {}\n",
    "\n",
    "    def _get_optimal_jobs(self):\n",
    "        \"\"\"Determinar el número óptimo de trabajos paralelos\"\"\"\n",
    "        import os\n",
    "        return min(4, os.cpu_count() - 1 if os.cpu_count() > 1 else 1)\n",
    "\n",
    "    def load_and_preprocess_data(self, train_path, test_path, max_features=100):\n",
    "        \"\"\"Cargar y preprocesar datos con selección de características\"\"\"\n",
    "        print(\"Cargando dataset RT-IoT2022...\")\n",
    "\n",
    "        # Cargar datos\n",
    "        train_df = pd.read_csv(train_path, low_memory=False)\n",
    "        test_df = pd.read_csv(test_path, low_memory=False)\n",
    "\n",
    "        print(f\"Dimensiones Train: {train_df.shape}\")\n",
    "        print(f\"Dimensiones Test: {test_df.shape}\")\n",
    "\n",
    "        # Optimizar uso de memoria\n",
    "        train_df = self._optimize_dataframe(train_df)\n",
    "        test_df = self._optimize_dataframe(test_df)\n",
    "\n",
    "        # Separar características y target\n",
    "        X_train = train_df.drop(\"Attack_type\", axis=1)\n",
    "        y_train = train_df[\"Attack_type\"]\n",
    "\n",
    "        if \"Attack_type\" in test_df.columns:\n",
    "            X_test = test_df.drop(\"Attack_type\", axis=1)\n",
    "            y_test = test_df[\"Attack_type\"]\n",
    "        else:\n",
    "            X_test = test_df\n",
    "            y_test = None\n",
    "\n",
    "        # Preprocesamiento con selección de características\n",
    "        X_train_processed, X_test_processed, y_train_encoded, y_test_encoded = (\n",
    "            self._preprocess_with_feature_selection(\n",
    "                X_train, X_test, y_train, y_test, max_features\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            X_train_processed,\n",
    "            X_test_processed,\n",
    "            y_train_encoded,\n",
    "            y_test_encoded,\n",
    "            y_test,\n",
    "        )\n",
    "\n",
    "    def _optimize_dataframe(self, df):\n",
    "        \"\"\"Optimizar tipos de datos para reducir uso de memoria\"\"\"\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_columns:\n",
    "            if df[col].dtype == \"float64\":\n",
    "                df[col] = df[col].astype(\"float32\")\n",
    "            elif df[col].dtype == \"int64\":\n",
    "                col_min = df[col].min()\n",
    "                col_max = df[col].max()\n",
    "                if col_min >= 0:\n",
    "                    if col_max < 256:\n",
    "                        df[col] = df[col].astype(\"uint8\")\n",
    "                    elif col_max < 65536:\n",
    "                        df[col] = df[col].astype(\"uint16\")\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(\"uint32\")\n",
    "                else:\n",
    "                    if col_min > -128 and col_max < 127:\n",
    "                        df[col] = df[col].astype(\"int8\")\n",
    "                    elif col_min > -32768 and col_max < 32767:\n",
    "                        df[col] = df[col].astype(\"int16\")\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(\"int32\")\n",
    "        return df\n",
    "\n",
    "    def _preprocess_with_feature_selection(\n",
    "        self, X_train, X_test, y_train, y_test, max_features\n",
    "    ):\n",
    "        \"\"\"Preprocesamiento con selección de características\"\"\"\n",
    "        print(\"Iniciando preprocesamiento con selección de características...\")\n",
    "\n",
    "        numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        categorical_features = X_train.select_dtypes(\n",
    "            include=[\"object\", \"bool\"]\n",
    "        ).columns.tolist()\n",
    "\n",
    "        print(f\"Características numéricas: {len(numeric_features)}\")\n",
    "        print(f\"Características categóricas: {len(categorical_features)}\")\n",
    "\n",
    "        # Codificar características categóricas\n",
    "        for col in categorical_features:\n",
    "            if col in X_train.columns:\n",
    "                le = LabelEncoder()\n",
    "                combined = pd.concat([X_train[col], X_test[col]], axis=0)\n",
    "                le.fit(combined.astype(str))\n",
    "                X_train[col] = le.transform(X_train[col].astype(str))\n",
    "                X_test[col] = le.transform(X_test[col].astype(str))\n",
    "\n",
    "        # Escalar características numéricas\n",
    "        X_train_scaled = X_train.copy()\n",
    "        X_test_scaled = X_test.copy()\n",
    "\n",
    "        if numeric_features:\n",
    "            X_train_scaled[numeric_features] = self.scaler.fit_transform(\n",
    "                X_train[numeric_features]\n",
    "            )\n",
    "            X_test_scaled[numeric_features] = self.scaler.transform(\n",
    "                X_test[numeric_features]\n",
    "            )\n",
    "\n",
    "        # Manejar valores NaN\n",
    "        X_train_scaled = X_train_scaled.fillna(0)\n",
    "        X_test_scaled = X_test_scaled.fillna(0)\n",
    "\n",
    "        # Selección de características para acelerar modelos\n",
    "        if self.use_feature_selection and X_train_scaled.shape[1] > max_features:\n",
    "            print(\n",
    "                f\"Aplicando selección de características: {X_train_scaled.shape[1]} -> {max_features}\"\n",
    "            )\n",
    "            self.feature_selector = SelectKBest(score_func=f_classif, k=max_features)\n",
    "            X_train_scaled = self.feature_selector.fit_transform(\n",
    "                X_train_scaled, y_train\n",
    "            )\n",
    "            X_test_scaled = self.feature_selector.transform(X_test_scaled)\n",
    "            print(f\"Dimensiones después de selección: {X_train_scaled.shape}\")\n",
    "\n",
    "        # Codificar target\n",
    "        y_train_encoded = self.label_encoder.fit_transform(y_train)\n",
    "        y_test_encoded = (\n",
    "            self.label_encoder.transform(y_test) if y_test is not None else None\n",
    "        )\n",
    "\n",
    "        print(\"Preprocesamiento completado\")\n",
    "        return X_train_scaled, X_test_scaled, y_train_encoded, y_test_encoded\n",
    "\n",
    "# =============================================================================\n",
    "# FUNCIÓN DE ANÁLISIS EXPLORATORIO\n",
    "# =============================================================================\n",
    "\n",
    "def complete_eda_analysis(X_train, X_test, y_train, y_test, label_encoder, dataset_name=\"RT-IoT2022\"):\n",
    "    \"\"\"\n",
    "    Análisis exploratorio completo para el dataset RT-IoT2022\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ANÁLISIS EXPLORATORIO COMPLETO - {dataset_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Convertir a DataFrames si son arrays numpy\n",
    "    if not isinstance(X_train, pd.DataFrame):\n",
    "        if hasattr(X_train, 'shape'):\n",
    "            feature_names = [f'Feature_{i}' for i in range(X_train.shape[1])]\n",
    "            X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "            X_test_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "        else:\n",
    "            print(\"Error: X_train no es un DataFrame ni un array numpy válido\")\n",
    "            return\n",
    "    else:\n",
    "        X_train_df = X_train.copy()\n",
    "        X_test_df = X_test.copy()\n",
    "        feature_names = X_train.columns.tolist()\n",
    "    \n",
    "    # Convertir labels a nombres originales\n",
    "    y_train_names = label_encoder.inverse_transform(y_train)\n",
    "    y_test_names = label_encoder.inverse_transform(y_test)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 1. DISTRIBUCIÓN DE CLASES\n",
    "    # =========================================================================\n",
    "    print(\"\\n1. GENERANDO DISTRIBUCIÓN DE CLASES...\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Train distribution\n",
    "    train_counts = pd.Series(y_train_names).value_counts()\n",
    "    bars1 = ax1.bar(range(len(train_counts)), train_counts.values, color='skyblue', edgecolor='black')\n",
    "    ax1.set_title('Distribución de Clases - Entrenamiento', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Tipo de Ataque')\n",
    "    ax1.set_ylabel('Número de Instancias')\n",
    "    ax1.set_xticks(range(len(train_counts)))\n",
    "    ax1.set_xticklabels(train_counts.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bar, count in zip(bars1, train_counts.values):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{count:,}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Test distribution\n",
    "    test_counts = pd.Series(y_test_names).value_counts()\n",
    "    bars2 = ax2.bar(range(len(test_counts)), test_counts.values, color='lightcoral', edgecolor='black')\n",
    "    ax2.set_title('Distribución de Clases - Prueba', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Tipo de Ataque')\n",
    "    ax2.set_ylabel('Número de Instancias')\n",
    "    ax2.set_xticks(range(len(test_counts)))\n",
    "    ax2.set_xticklabels(test_counts.index, rotation=45, ha='right')\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bar, count in zip(bars2, test_counts.values):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{count:,}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. HISTOGRAMAS DE CARACTERÍSTICAS NUMÉRICAS\n",
    "    # =========================================================================\n",
    "    print(\"\\n2. GENERANDO HISTOGRAMAS DE CARACTERÍSTICAS...\")\n",
    "    \n",
    "    # Seleccionar solo características numéricas\n",
    "    numeric_features = X_train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    if len(numeric_features) > 12:\n",
    "        selected_features = np.random.choice(numeric_features, 12, replace=False)\n",
    "    else:\n",
    "        selected_features = numeric_features[:min(12, len(numeric_features))]\n",
    "    \n",
    "    n_cols = 4\n",
    "    n_rows = (len(selected_features) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    for i, feature in enumerate(selected_features):\n",
    "        if feature in X_train_df.columns:\n",
    "            axes[i].hist(X_train_df[feature].values, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            axes[i].set_title(f'Distribución de {feature}', fontsize=12, fontweight='bold')\n",
    "            axes[i].set_xlabel('Valor')\n",
    "            axes[i].set_ylabel('Frecuencia')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ocultar ejes vacíos\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 3. BOXPLOTS POR CLASE\n",
    "    # =========================================================================\n",
    "    print(\"\\n3. GENERANDO BOXPLOTS POR CLASE...\")\n",
    "    \n",
    "    # Seleccionar 6 características importantes para boxplots\n",
    "    if len(numeric_features) >= 6:\n",
    "        important_features = numeric_features[:6]\n",
    "    else:\n",
    "        important_features = numeric_features\n",
    "    \n",
    "    n_cols = 2\n",
    "    n_rows = (len(important_features) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 6*n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if n_cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    # Crear DataFrame temporal para boxplots\n",
    "    temp_df = X_train_df[important_features].copy()\n",
    "    temp_df['class'] = y_train_names\n",
    "    \n",
    "    for i, feature in enumerate(important_features):\n",
    "        if feature in X_train_df.columns:\n",
    "            # Boxplot\n",
    "            sns.boxplot(data=temp_df, x='class', y=feature, ax=axes[i])\n",
    "            axes[i].set_title(f'Distribución de {feature} por Clase', fontsize=12, fontweight='bold')\n",
    "            axes[i].set_xlabel('Clase')\n",
    "            axes[i].set_ylabel(feature)\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ocultar ejes vacíos\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 4. MATRIZ DE CORRELACIÓN\n",
    "    # =========================================================================\n",
    "    print(\"\\n4. GENERANDO MATRIZ DE CORRELACIÓN...\")\n",
    "    \n",
    "    # Seleccionar solo características numéricas y limitar a 20 para mejor visualización\n",
    "    if len(numeric_features) > 20:\n",
    "        selected_features = numeric_features[:20]\n",
    "    else:\n",
    "        selected_features = numeric_features\n",
    "    \n",
    "    # Calcular matriz de correlación\n",
    "    corr_matrix = X_train_df[selected_features].corr()\n",
    "    \n",
    "    plt.figure(figsize=(16, 14))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # Máscara para el triángulo superior\n",
    "    heatmap = sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                         center=0, square=True, cbar_kws={\"shrink\": .8}, annot_kws={\"size\": 8})\n",
    "    plt.title('Matriz de Correlación de Características', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Identificar correlaciones altas\n",
    "    high_corr = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_value = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_value) > 0.8:\n",
    "                high_corr.append((\n",
    "                    corr_matrix.columns[i], \n",
    "                    corr_matrix.columns[j], \n",
    "                    corr_value\n",
    "                ))\n",
    "    \n",
    "    if high_corr:\n",
    "        print(\"\\nCORRELACIONES ALTAS (>0.8):\")\n",
    "        for feat1, feat2, corr in sorted(high_corr, key=lambda x: abs(x[2]), reverse=True):\n",
    "            print(f\"  {feat1} - {feat2}: {corr:.3f}\")\n",
    "    else:\n",
    "        print(\"\\nNo se encontraron correlaciones altas (>0.8)\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 5. ESTADÍSTICAS DESCRIPTIVAS\n",
    "    # =========================================================================\n",
    "    print(\"\\n5. GENERANDO ESTADÍSTICAS DESCRIPTIVAS...\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ESTADÍSTICAS DESCRIPTIVAS - DATASET RT-IoT2022\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Estadísticas generales\n",
    "    print(f\"\\n1. ESTADÍSTICAS GENERALES:\")\n",
    "    print(f\"   - Total de instancias entrenamiento: {X_train_df.shape[0]:,}\")\n",
    "    print(f\"   - Total de instancias prueba: {X_test_df.shape[0]:,}\")\n",
    "    print(f\"   - Total de características: {X_train_df.shape[1]}\")\n",
    "    print(f\"   - Número de clases: {len(label_encoder.classes_)}\")\n",
    "    \n",
    "    # Estadísticas por clase\n",
    "    print(f\"\\n2. DISTRIBUCIÓN POR CLASE:\")\n",
    "    train_class_counts = pd.Series(y_train_names).value_counts()\n",
    "    test_class_counts = pd.Series(y_test_names).value_counts()\n",
    "    \n",
    "    print(f\"\\n   ENTRENAMIENTO:\")\n",
    "    for class_name in train_class_counts.index:\n",
    "        count = train_class_counts[class_name]\n",
    "        percentage = (count / len(y_train)) * 100\n",
    "        print(f\"     - {class_name}: {count:,} instancias ({percentage:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\n   PRUEBA:\")\n",
    "    for class_name in test_class_counts.index:\n",
    "        count = test_class_counts[class_name]\n",
    "        percentage = (count / len(y_test)) * 100\n",
    "        print(f\"     - {class_name}: {count:,} instancias ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Estadísticas numéricas\n",
    "    print(f\"\\n3. ESTADÍSTICAS NUMÉRICAS (Primeras 10 características):\")\n",
    "    numeric_stats = X_train_df.describe()\n",
    "    print(numeric_stats.iloc[:, :10])  # Mostrar solo primeras 10 columnas\n",
    "    \n",
    "    # Valores nulos\n",
    "    print(f\"\\n4. ANÁLISIS DE VALORES NULOS:\")\n",
    "    train_null_counts = X_train_df.isnull().sum()\n",
    "    test_null_counts = X_test_df.isnull().sum()\n",
    "    \n",
    "    if train_null_counts.sum() == 0 and test_null_counts.sum() == 0:\n",
    "        print(\"   - No hay valores nulos en ningún dataset\")\n",
    "    else:\n",
    "        print(\"   ENTRENAMIENTO:\")\n",
    "        for col, null_count in train_null_counts[train_null_counts > 0].items():\n",
    "            percentage = (null_count / len(X_train_df)) * 100\n",
    "            print(f\"     - {col}: {null_count} valores nulos ({percentage:.2f}%)\")\n",
    "        \n",
    "        print(\"   PRUEBA:\")\n",
    "        for col, null_count in test_null_counts[test_null_counts > 0].items():\n",
    "            percentage = (null_count / len(X_test_df)) * 100\n",
    "            print(f\"     - {col}: {null_count} valores nulos ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Información de tipos de datos\n",
    "    print(f\"\\n5. INFORMACIÓN DE TIPOS DE DATOS:\")\n",
    "    print(X_train_df.dtypes.value_counts())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANÁLISIS EXPLORATORIO COMPLETADO\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        'correlation_matrix': corr_matrix,\n",
    "        'descriptive_stats': numeric_stats,\n",
    "        'class_distribution_train': train_class_counts,\n",
    "        'class_distribution_test': test_class_counts,\n",
    "        'high_correlations': high_corr\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"INICIANDO CARGA DE DATOS CON RTIoTClassifier...\")\n",
    "\n",
    "# Crear instancia del clasificador\n",
    "classifier = RTIoTClassifier(n_jobs=-1, use_feature_selection=True)\n",
    "\n",
    "# NOTA: Reemplaza estas rutas con las rutas reales de tus archivos CSV\n",
    "train_path = \"train.csv\"  # Cambia por tu ruta real\n",
    "test_path = \"test.csv\"    # Cambia por tu ruta real\n",
    "\n",
    "try:\n",
    "    # Cargar y preprocesar datos\n",
    "    (X_train_processed, X_test_processed, \n",
    "     y_train_encoded, y_test_encoded, y_test_original) = classifier.load_and_preprocess_data(\n",
    "        train_path, test_path, max_features=50\n",
    "    )\n",
    "    \n",
    "    print(\"¡Datos cargados y preprocesados exitosamente!\")\n",
    "    print(f\"Dimensiones X_train: {X_train_processed.shape}\")\n",
    "    print(f\"Dimensiones X_test: {X_test_processed.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error cargando datos reales: {e}\")\n",
    "    print(\"Usando datos de ejemplo para demostración...\")\n",
    "    \n",
    "    # Crear datos de ejemplo si no hay archivos reales\n",
    "    np.random.seed(42)\n",
    "    n_samples_train = 1000\n",
    "    n_samples_test = 300\n",
    "    n_features = 50\n",
    "    \n",
    "    # Datos de entrenamiento de ejemplo\n",
    "    X_train_processed = np.random.randn(n_samples_train, n_features)\n",
    "    X_test_processed = np.random.randn(n_samples_test, n_features)\n",
    "    \n",
    "    # Etiquetas de ejemplo (simulando las 12 clases)\n",
    "    classes = ['Normal', 'ARP_poisioning', 'DOS_SYN_Hping', 'MQTT_Publish', \n",
    "               'NMAP_TCP_scan', 'NMAP_UDP_SCAN', 'Thing_Speak', 'Wipro_bulb',\n",
    "               'DDOS_Slowloris', 'NMAP_OS_DETECTION', 'NMAP_XMAS_TREE_SCAN', 'NMAP_FIN_SCAN']\n",
    "    \n",
    "    # Crear label encoder para datos de ejemplo\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    classifier.label_encoder = le\n",
    "    \n",
    "    y_train_encoded = np.random.choice(len(classes), n_samples_train)\n",
    "    y_test_encoded = np.random.choice(len(classes), n_samples_test)\n",
    "\n",
    "# =============================================================================\n",
    "# EJECUTAR ANÁLISIS EXPLORATORIO COMPLETO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EJECUTANDO ANÁLISIS EXPLORATORIO COMPLETO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ejecutar EDA completo\n",
    "resultados_eda = complete_eda_analysis(\n",
    "    X_train=X_train_processed,\n",
    "    X_test=X_test_processed, \n",
    "    y_train=y_train_encoded,\n",
    "    y_test=y_test_encoded,\n",
    "    label_encoder=classifier.label_encoder,\n",
    "    dataset_name=\"RT-IoT2022\"\n",
    ")\n",
    "\n",
    "print(\"¡Proceso completado exitosamente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
